{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h42wJWAi2Uir"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque \n",
        "import sys \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Trader:\n",
        "    def __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
        "        self.state_size = state_size # normalized previous days\n",
        "        self.action_size = 3 # hold, buy, sell\n",
        "        self.memory = deque(maxlen=1000)\n",
        "        self.inventory = []\n",
        "        self.model_name = model_name\n",
        "        self.is_eval = is_eval\n",
        "        self.gamma = 0.95    #Q = r(s, a) + Gamma(max(Q(s, a))) \n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.model = load_model(model_name) if is_eval else self._model()\n",
        "    \n",
        "    def _model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
        "        model.add(Dense(units=32, activation=\"relu\"))\n",
        "        model.add(Dense(units=8, activation=\"relu\"))\n",
        "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
        "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
        "        return model\n",
        "    \n",
        "    def act(self, state):\n",
        "        if not self.is_eval and random.random() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        options = self.model.predict(state)\n",
        "        return np.argmax(options[0])\n",
        "    \n",
        "    def expReplay(self, batch_size):\n",
        "        mini_batch = []\n",
        "        l = len(self.memory)\n",
        "        for i in range(l - batch_size + 1, l):\n",
        "            mini_batch.append(self.memory[i])\n",
        "        for state, action, reward, next_state, done in mini_batch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------\n",
        "\n",
        "# HELPER FUNCTIONS\n",
        "\n",
        "def formatPrice(n):\n",
        "  return(\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
        "\n",
        "def getStockDataVec(key):\n",
        "  og_data = []\n",
        "  d1 = []\n",
        "  d2 = []\n",
        "  data = []\n",
        "  #rsi = []\n",
        "  lines = open(key+\".csv\",\"r\").read().splitlines()\n",
        "  for line in lines[15:]:\n",
        "    d1.append(line.split(\",\")[0])\n",
        "    d2.append(float(line.split(\",\")[1]))\n",
        "    data.append(float(line.split(\",\")[1]))\n",
        "    #rsi.append(float(line.split(\",\")[8])) \n",
        "  og_data.append(d1)\n",
        "  og_data.append(d2) \n",
        "  return data, og_data  \n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+math.exp(-x))\n",
        "\n",
        "def getState(data, t, n): #getState(data, rsi, t, n)\n",
        "  d = t - n + 1\n",
        "  if d >= 0:\n",
        "      block1 = data[d:t+1]\n",
        "      #block2 = rsi[d:t+1] \n",
        "  else:\n",
        "      block1 = -d * [data[0]] + data[0:t+1] # pad with t0\n",
        "      #block2 = -d * [rsi[0]] + rsi[0:t+1] # pad with t0\n",
        "  res = []\n",
        "  for i in range(n-1):\n",
        "      res.append((sigmoid(block1[i+1] - block1[i]))) \n",
        "  return np.array([res])\n",
        "\n",
        "def plot_decisions(buys, sells, data):\n",
        "  length = len(data[0])\n",
        "  weeks = []\n",
        "  for i in range(1, length+1):\n",
        "    weeks.append(i)\n",
        "  # Line Plot of Market Data\n",
        "  # Line color should be blue\n",
        "  plt.plot(weeks, data[1], color='black') # need to fill in \n",
        "\n",
        "  # Deep Q scatter color is red\n",
        "  plt.scatter(buys[0], buys[1], marker='^', color='red')\n",
        "  plt.scatter(sells[0], sells[1], marker='v', color='blue')\n",
        "\n",
        "  # Labels Design\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Adjusted Close') \n",
        "  plt.title('Buy Sell Times')\n",
        "\n",
        "  # Display Plot \n",
        "  plt.show()\n",
        "\n",
        "def plot_accumulating_profits(deep_Q_profits):\n",
        "  deep_Q_accumulating_profits = accumulating_loop(deep_Q_profits)\n",
        "\n",
        "  # Plots \n",
        "  plt.plot(deep_Q_profits[0], deep_Q_accumulating_profits, color='red')\n",
        "\n",
        "  # Labels Design\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Profit')\n",
        "  plt.title('Accumulating Profits')\n",
        "\n",
        "  # Display Plot\n",
        "  plt.show()\n",
        "    \n",
        "def accumulating_loop(profits):\n",
        "  accumulating_profits = [profits[1][0]]\n",
        "  for i in range(1, len(profits[1])):\n",
        "    accumulating_profits.append(profits[1][i] + accumulating_profits[i-1]) \n",
        "  return accumulating_profits \n",
        "    \n",
        "def plot_profits(deep_Q_profits):\n",
        "  length = len(deepQ_profits[0])\n",
        "  weeks = []\n",
        "  for i in range(1, length+1):\n",
        "    weeks.append(i)\n",
        "  # Plots \n",
        "  plt.plot(deep_Q_profits[0], deep_Q_profits[1], color='red')\n",
        "\n",
        "  # Labels Design\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Profit')\n",
        "  plt.title('Weekly Profits')\n",
        "\n",
        "  # Display Plot\n",
        "  plt.show()\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------\n",
        "\n",
        "stock_name = \"/content/sample_data/JPY\" \n",
        "window_size = int(input(\"Enter window_size, Episode_count, Starting Balance(must > 30,000), Risk(5% = 0.05)\\n\"))\n",
        "episode_count = int(input()) # amount of times we run through the entire training set \n",
        "pre_balance = int(input()) # amount the trader starts with \n",
        "risk = float(input()) # amount of risk per trade \n",
        "trader = Trader(window_size)\n",
        "data, og_data = getStockDataVec(stock_name)\n",
        "length = len(data) - 1\n",
        "batch_size = 32\n",
        "buys = []\n",
        "sells = []\n",
        "profits = []\n",
        "for e in range(1, episode_count + 1):\n",
        "  print(\"Episode: \" + str(e) + \"/\" + str(episode_count))\n",
        "  state = getState(data, 0, window_size + 1) \n",
        "  total_profit = 0\n",
        "  trader.inventory = []\n",
        "  stocks_bought = []\n",
        "  post_balance = pre_balance \n",
        "  buy_times = []\n",
        "  buy_price = []\n",
        "  sell_times = []\n",
        "  sell_price = []\n",
        "  profit_list = []\n",
        "  profit_date = []\n",
        "  for t in range(length):\n",
        "    print(\"working\")\n",
        "    action = trader.act(state)\n",
        "    # hold\n",
        "    next_state = getState(data, t+1, window_size + 1) \n",
        "    reward = 0\n",
        "        \n",
        "    if action == 1 and post_balance > data[t]: # bought\n",
        "      bought_price = data[t] \n",
        "      #bought_time = og_data[0][t] \n",
        "      bought_time = t\n",
        "      #print(\"stock_price: \" + formatPrice(bought_price)) \n",
        "      money_to_trade = post_balance * risk \n",
        "      stock_amount = int(money_to_trade / bought_price) \n",
        "      trader.inventory.append(bought_price)\n",
        "      stocks_bought.append(stock_amount)\n",
        "      post_balance = post_balance - (stock_amount * bought_price)\n",
        "      if e % episode_count == 0:\n",
        "        buy_times.append(bought_time)\n",
        "        buy_price.append(bought_price)\n",
        "    elif action == 2 and len(trader.inventory) > 0: # sold \n",
        "      sold_price = data[t]  \n",
        "      #sold_time = og_data[0][t]\n",
        "      sold_time = t \n",
        "      bought_price = window_size_price = trader.inventory.pop(0)\n",
        "      stock_amount = stocks_bought.pop(0) \n",
        "      profit = (sold_price * stock_amount) - (bought_price * stock_amount)\n",
        "      reward = max(profit, 0)\n",
        "      #total_profit += data[t] - bought_price\n",
        "      #total_profit += profit \n",
        "      post_balance = post_balance + (sold_price * stock_amount)\n",
        "      if e % episode_count == 0:\n",
        "        sell_times.append(sold_time)\n",
        "        sell_price.append(sold_price)\n",
        "        profit_list.append(profit)\n",
        "        profit_date.append(sold_time)\n",
        "         \n",
        "    if t == length-1:\n",
        "      done = True\n",
        "    else:\n",
        "      done = False \n",
        "\n",
        "    trader.memory.append((state, action, reward, next_state, done))\n",
        "    state = next_state\n",
        "\n",
        "    if done:\n",
        "      if e % episode_count == 0:\n",
        "        buys.append(buy_times)\n",
        "        buys.append(buy_price)\n",
        "        sells.append(sell_times)\n",
        "        sells.append(sell_price)\n",
        "        profits.append(profit_date)\n",
        "        profits.append(profit_list)\n",
        "\n",
        "    if len(trader.memory) > batch_size:\n",
        "      trader.expReplay(batch_size)\n",
        "\n",
        "  if e % episode_count == 0:\n",
        "    trader.model.save(str(e))\n",
        "\n",
        "deepQ_buys = [buys[0], buys[1]]\n",
        "deepQ_sells = [sells[0], sells[1]]\n",
        "deepQ_profits = [profits[0], profits[1]] \n",
        "\n",
        "plot_decisions(deepQ_buys, deepQ_sells, og_data)\n",
        "\n",
        "plot_accumulating_profits(deepQ_profits)\n",
        "\n",
        "plot_profits(deepQ_profits) "
      ]
    }
  ]
}